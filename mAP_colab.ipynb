{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mAP\n",
    "\n",
    "## copy from https://github.com/Cartucho/mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "#'''\n",
    "#这里设置的门限值较低是因为计算map需要用到不同门限条件下的Recall和Precision值。\n",
    "#所以只有保留的框足够多，计算的map才会更精确，详情可以了解map的原理。\n",
    "#计算map时输出的Recall和Precision值指的是门限为0.5时的Recall和Precision值。\n",
    "\n",
    "#此处获得的./input/detection-results/里面的txt的框的数量会比直接predict多一些，这是因为这里的门限低，\n",
    "#目的是为了计算不同门限条件下的Recall和Precision值，从而实现map的计算。\n",
    "\n",
    "#这里的self.iou指的是非极大抑制所用到的iou，具体的可以了解非极大抑制的原理，\n",
    "#如果低分框与高分框的iou大于这里设定的self.iou，那么该低分框将会被剔除。\n",
    "\n",
    "#可能有些同学知道有0.5和0.5:0.95的mAP，这里的self.iou=0.5不代表mAP0.5。\n",
    "#如果想要设定mAP0.x，比如设定mAP0.75，可以去get_map.py设定MINOVERLAP。\n",
    "#'''\n",
    "class mAP_FRCNN(FRCNN):\n",
    "    \n",
    "    #   检测图片\n",
    "    def detect_image(self,image_id,image):\n",
    "        self.confidence = 0.01\n",
    "        self.iou        = 0.45\n",
    "        f = open(\"D:/final project/input/detection-results/\"+image_id+\".txt\",\"w\") \n",
    "        \n",
    "        #   转换成RGB图片，可以用于灰度图预测。\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "        old_width, old_height = image_shape[1], image_shape[0]\n",
    "        old_image = copy.deepcopy(image)\n",
    "        \n",
    "        #   给原图像进行resize，resize到短边为600的大小上\n",
    "        width,height = get_new_img_size(old_width, old_height)\n",
    "        image = image.resize([width,height], Image.BICUBIC)\n",
    "\n",
    "        #   图片预处理，归一化。\n",
    "        photo = np.transpose(np.array(image,dtype = np.float32)/255, (2, 0, 1))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(np.asarray([photo]))\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "\n",
    "            roi_cls_locs, roi_scores, rois, _ = self.model(images)\n",
    "\n",
    "            #   利用classifier的预测结果对建议框进行解码，获得预测框\n",
    "            outputs = self.decodebox.forward(roi_cls_locs[0], roi_scores[0], rois, height = height, width = width, nms_iou = self.iou, score_thresh = self.confidence)\n",
    "            #   如果没有检测出物体，返回原图\n",
    "            if len(outputs)==0:\n",
    "                return old_image\n",
    "            outputs = np.array(outputs)\n",
    "            bbox = outputs[:,:4]\n",
    "            label = outputs[:, 4]\n",
    "            conf = outputs[:, 5]\n",
    "\n",
    "            bbox[:, 0::2] = (bbox[:, 0::2]) / width * old_width\n",
    "            bbox[:, 1::2] = (bbox[:, 1::2]) / height * old_height\n",
    "            \n",
    "        for i, c in enumerate(label):\n",
    "            predicted_class = self.class_names[int(c)]\n",
    "            score = str(conf[i])\n",
    "\n",
    "            left, top, right, bottom = bbox[i]\n",
    "            f.write(\"%s %s %s %s %s %s\\n\" % (predicted_class, score[:6], str(int(left)), str(int(top)), str(int(right)),str(int(bottom))))\n",
    "\n",
    "        f.close()\n",
    "        return \n",
    "\n",
    "fffrcnn = mAP_FRCNN()\n",
    "image_ids = open('D:/final project/VOC/ImageSets/Main/test.txt').read().strip().split()\n",
    "\n",
    "if not os.path.exists(\"D:/final project/input/\"):\n",
    "    os.makedirs(\"D:/final project/input/\")\n",
    "if not os.path.exists(\"D:/final project/input/detection-results\"):\n",
    "    os.makedirs(\"D:/final project/input/detection-results\")\n",
    "if not os.path.exists(\"D:/final project/input/Images-optional\"):\n",
    "    os.makedirs('D:/final project/input/Images-optional\")\n",
    "\n",
    "for image_id in tqdm(image_ids):\n",
    "    image_path = \"D:/final project/VOC/JPEGImages/\"+image_id+\".png\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert(\"RGB\")\n",
    "    image.save(\"D:/final project/input/Images-optional/\"+image_id+\".png\")\n",
    "    fffrcnn.detect_image(image_id,image)\n",
    "    \n",
    "print(\"Conversion completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.13% = licence AP \t||\tscore_threhold=0.5 : F1=0.76 ; Recall=90.00% ; Precision=65.22%\n",
      "mAP = 85.13%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#如果想要设定mAP0.x，比如计算mAP0.75，可以设定MINOVERLAP = 0.75。\n",
    "MINOVERLAP = 0.5\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-na', '--no-animation', help=\"no animation is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-np', '--no-plot', help=\"no plot is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-q', '--quiet', help=\"minimalistic console output.\", action=\"store_true\")\n",
    "parser.add_argument('-i', '--ignore', nargs='+', type=str, help=\"ignore a list of classes.\")\n",
    "parser.add_argument('--set-class-iou', nargs='+', type=str, help=\"set IoU for a specific class.\")\n",
    "#args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "#'''\n",
    "#    0,0 ------> x (width)\n",
    "#     |\n",
    "#     |  (Left,Top)\n",
    "#     |      *_________\n",
    "#     |      |         |\n",
    "#            |         |\n",
    "#     y      |_________|\n",
    "#  (height)            *\n",
    "#                (Right,Bottom)\n",
    "#'''\n",
    "\n",
    "if args.ignore is None:\n",
    "    args.ignore = []\n",
    "\n",
    "specific_iou_flagged = False\n",
    "if args.set_class_iou is not None:\n",
    "    specific_iou_flagged = True\n",
    "\n",
    "#os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "GT_PATH = os.path.join('D:/final project/input/ground-truth')\n",
    "DR_PATH = os.path.join('D:/final project/input/detection-results')\n",
    "IMG_PATH = os.path.join('D:/final project/input/Images-optional')\n",
    "if os.path.exists(IMG_PATH): \n",
    "    for dirpath, dirnames, files in os.walk(IMG_PATH):\n",
    "        if not files:\n",
    "            args.no_animation = True\n",
    "else:\n",
    "    args.no_animation = True\n",
    "\n",
    "show_animation = False\n",
    "if not args.no_animation:\n",
    "    try:\n",
    "        import cv2\n",
    "        show_animation = True\n",
    "    except ImportError:\n",
    "        print(\"\\\"opencv-python\\\" not found, please install to visualize the results.\")\n",
    "        args.no_animation = True\n",
    "\n",
    "draw_plot = False\n",
    "if not args.no_plot:\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        draw_plot = True\n",
    "    except ImportError:\n",
    "        print(\"\\\"matplotlib\\\" not found, please install it to get the resulting plots.\")\n",
    "        args.no_plot = True\n",
    "\n",
    "\n",
    "def log_average_miss_rate(precision, fp_cumsum, num_images):\n",
    "#    \"\"\"\n",
    "#        log-average miss rate:\n",
    "#            Calculated by averaging miss rates at 9 evenly spaced FPPI points\n",
    "#            between 10e-2 and 10e0, in log-space.\n",
    "\n",
    "#        output:\n",
    "#                lamr | log-average miss rate\n",
    "#                mr | miss rate\n",
    "#                fppi | false positives per image\n",
    "\n",
    "#       references:\n",
    "#           [1] Dollar, Piotr, et al. \"Pedestrian Detection: An Evaluation of the\n",
    "#              State of the Art.\" Pattern Analysis and Machine Intelligence, IEEE\n",
    "#              Transactions on 34.4 (2012): 743 - 761.\n",
    "#    \"\"\"\n",
    "\n",
    "    if precision.size == 0:\n",
    "        lamr = 0\n",
    "        mr = 1\n",
    "        fppi = 0\n",
    "        return lamr, mr, fppi\n",
    "\n",
    "    fppi = fp_cumsum / float(num_images)\n",
    "    mr = (1 - precision)\n",
    "\n",
    "    fppi_tmp = np.insert(fppi, 0, -1.0)\n",
    "    mr_tmp = np.insert(mr, 0, 1.0)\n",
    "\n",
    "    ref = np.logspace(-2.0, 0.0, num = 9)\n",
    "    for i, ref_i in enumerate(ref):\n",
    "        j = np.where(fppi_tmp <= ref_i)[-1][-1]\n",
    "        ref[i] = mr_tmp[j]\n",
    "\n",
    "    lamr = math.exp(np.mean(np.log(np.maximum(1e-10, ref))))\n",
    "\n",
    "    return lamr, mr, fppi\n",
    "\n",
    "#\"\"\"\n",
    "# throw error and exit\n",
    "#\"\"\"\n",
    "def error(msg):\n",
    "    print(msg)\n",
    "    sys.exit(0)\n",
    "\n",
    "#\"\"\"\n",
    "# check if the number is a float between 0.0 and 1.0\n",
    "#\"\"\"\n",
    "def is_float_between_0_and_1(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "        if val > 0.0 and val < 1.0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "#\"\"\"\n",
    "# Calculate the AP given the recall and precision array\n",
    "#    1st) We compute a version of the measured precision/recall curve with\n",
    "#        precision monotonically decreasing\n",
    "#    2nd) We compute the AP as the area under this curve by numerical integration.\n",
    "#\"\"\"\n",
    "def voc_ap(rec, prec):\n",
    "#    \"\"\"\n",
    " #   --- Official matlab code VOC2012---\n",
    "#    mrec=[0 ; rec ; 1];\n",
    "#    mpre=[0 ; prec ; 0];\n",
    "#    for i=numel(mpre)-1:-1:1\n",
    "#            mpre(i)=max(mpre(i),mpre(i+1));\n",
    "#    end\n",
    "#    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "#    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "#    \"\"\"\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "#    \"\"\"\n",
    "#     This part makes the precision monotonically decreasing\n",
    "#        (goes from the end to the beginning)\n",
    "#        matlab: for i=numel(mpre)-1:-1:1\n",
    "#                    mpre(i)=max(mpre(i),mpre(i+1));\n",
    "#    \"\"\"\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    " #   \"\"\"\n",
    " #    This part creates a list of indexes where the recall changes\n",
    " #       matlab: i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    " #   \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    " #   \"\"\"\n",
    " #    The Average Precision (AP) is the area under the curve\n",
    " #       (numerical integration)\n",
    " #       matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    " #   \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "# Convert the lines of a file to a list\n",
    "#\"\"\"\n",
    "def file_lines_to_list(path):\n",
    "    # open txt file lines to a list\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    return content\n",
    "\n",
    "#\"\"\"\n",
    "# Draws text in image\n",
    "#\"\"\"\n",
    "def draw_text_in_image(img, text, pos, color, line_width):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    fontScale = 1\n",
    "    lineType = 1\n",
    "    bottomLeftCornerOfText = pos\n",
    "    cv2.putText(img, text,\n",
    "            bottomLeftCornerOfText,\n",
    "            font,\n",
    "            fontScale,\n",
    "            color,\n",
    "            lineType)\n",
    "    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n",
    "    return img, (line_width + text_width)\n",
    "\n",
    "#\"\"\"\n",
    "# Plot - adjust axes\n",
    "#\"\"\"\n",
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])\n",
    "\n",
    "#\"\"\"\n",
    "# Draw plot using Matplotlib\n",
    "#\"\"\"\n",
    "def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color, true_p_bar):\n",
    "    # sort the dictionary by decreasing value, into a list of tuples\n",
    "    sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    # unpacking the list of tuples into two lists\n",
    "    sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n",
    "    # \n",
    "    if true_p_bar != \"\":\n",
    "#        \"\"\"\n",
    "#         Special case to draw in:\n",
    "#            - green -> TP: True Positives (object detected and matches ground-truth)\n",
    "#            - red -> FP: False Positives (object detected but does not match ground-truth)\n",
    "#            - orange -> FN: False Negatives (object not detected but present in the ground-truth)\n",
    "#        \"\"\"\n",
    "        fp_sorted = []\n",
    "        tp_sorted = []\n",
    "        for key in sorted_keys:\n",
    "            fp_sorted.append(dictionary[key] - true_p_bar[key])\n",
    "            tp_sorted.append(true_p_bar[key])\n",
    "        plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Positive')\n",
    "        plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Positive', left=fp_sorted)\n",
    "        # add legend\n",
    "        plt.legend(loc='lower right')\n",
    "#        \"\"\"\n",
    "#         Write number on side of bar\n",
    "#        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            fp_val = fp_sorted[i]\n",
    "            tp_val = tp_sorted[i]\n",
    "            fp_str_val = \" \" + str(fp_val)\n",
    "            tp_str_val = fp_str_val + \" \" + str(tp_val)\n",
    "            # trick to paint multicolor with offset:\n",
    "            # first paint everything and then repaint the first number\n",
    "            t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n",
    "            plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    else:\n",
    "        plt.barh(range(n_classes), sorted_values, color=plot_color)\n",
    "#        \"\"\"\n",
    "#         Write number on side of bar\n",
    "#        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            str_val = \" \" + str(val) # add a space before\n",
    "            if val < 1.0:\n",
    "                str_val = \" {0:.2f}\".format(val)\n",
    "            t = plt.text(val, i, str_val, color=plot_color, va='center', fontweight='bold')\n",
    "            # re-set axes to show number inside the figure\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    # set window title\n",
    "    fig.canvas.set_window_title(window_title)\n",
    "    # write classes in y axis\n",
    "    tick_font_size = 12\n",
    "    plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n",
    "#    \"\"\"\n",
    "#     Re-scale height accordingly\n",
    "#    \"\"\"\n",
    "    init_height = fig.get_figheight()\n",
    "    # comput the matrix height in points and inches\n",
    "    dpi = fig.dpi\n",
    "    height_pt = n_classes * (tick_font_size * 1.4) # 1.4 (some spacing)\n",
    "    height_in = height_pt / dpi\n",
    "    # compute the required figure height \n",
    "    top_margin = 0.15 # in percentage of the figure height\n",
    "    bottom_margin = 0.05 # in percentage of the figure height\n",
    "    figure_height = height_in / (1 - top_margin - bottom_margin)\n",
    "    # set new height\n",
    "    if figure_height > init_height:\n",
    "        fig.set_figheight(figure_height)\n",
    "\n",
    "    # set plot title\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    # set axis titles\n",
    "    # plt.xlabel('classes')\n",
    "    plt.xlabel(x_label, fontsize='large')\n",
    "    # adjust size of window\n",
    "    fig.tight_layout()\n",
    "    # save the plot\n",
    "    fig.savefig(output_path)\n",
    "    # show image\n",
    "    if to_show:\n",
    "        plt.show()\n",
    "    # close the plot\n",
    "    plt.close()\n",
    "\n",
    "#\"\"\"\n",
    "# Create a \".temp_files/\" and \"results/\" directory\n",
    "#\"\"\"\n",
    "TEMP_FILES_PATH = \".temp_files\"\n",
    "if not os.path.exists(TEMP_FILES_PATH): # if it doesn't exist already\n",
    "    os.makedirs(TEMP_FILES_PATH)\n",
    "results_files_path = \"results\"\n",
    "if os.path.exists(results_files_path): # if it exist already\n",
    "    # reset the results directory\n",
    "    shutil.rmtree(results_files_path)\n",
    "\n",
    "os.makedirs(results_files_path)\n",
    "if draw_plot:\n",
    "    os.makedirs(os.path.join(results_files_path, \"AP\"))\n",
    "    os.makedirs(os.path.join(results_files_path, \"F1\"))\n",
    "    os.makedirs(os.path.join(results_files_path, \"Recall\"))\n",
    "    os.makedirs(os.path.join(results_files_path, \"Precision\"))\n",
    "if show_animation:\n",
    "    os.makedirs(os.path.join(results_files_path, \"images\", \"detections_one_by_one\"))\n",
    "\n",
    "#\"\"\"\n",
    "# ground-truth\n",
    "#     Load each of the ground-truth files into a temporary \".json\" file.\n",
    "#     Create a list of all the class names present in the ground-truth (gt_classes).\n",
    "#\"\"\"\n",
    "# get a list with the ground-truth files\n",
    "ground_truth_files_list = glob.glob(GT_PATH + '/*.txt')\n",
    "if len(ground_truth_files_list) == 0:\n",
    "    error(\"Error: No ground-truth files found!\")\n",
    "ground_truth_files_list.sort()\n",
    "# dictionary with counter per class\n",
    "gt_counter_per_class = {}\n",
    "counter_images_per_class = {}\n",
    "\n",
    "for txt_file in ground_truth_files_list:\n",
    "    #print(txt_file)\n",
    "    file_id = txt_file.split(\".txt\", 1)[0]\n",
    "    file_id = os.path.basename(os.path.normpath(file_id))\n",
    "    # check if there is a correspondent detection-results file\n",
    "    temp_path = os.path.join(DR_PATH, (file_id + \".txt\"))\n",
    "    if not os.path.exists(temp_path):\n",
    "        error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "        error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "        error(error_msg)\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    # create ground-truth dictionary\n",
    "    bounding_boxes = []\n",
    "    is_difficult = False\n",
    "    already_seen_classes = []\n",
    "    for line in lines_list:\n",
    "        try:\n",
    "            if \"difficult\" in line:\n",
    "                class_name, left, top, right, bottom, _difficult = line.split()\n",
    "                is_difficult = True\n",
    "            else:\n",
    "                class_name, left, top, right, bottom = line.split()\n",
    "                    \n",
    "        except:\n",
    "            if \"difficult\" in line:\n",
    "                line_split = line.split()\n",
    "                _difficult = line_split[-1]\n",
    "                bottom = line_split[-2]\n",
    "                right = line_split[-3]\n",
    "                top = line_split[-4]\n",
    "                left = line_split[-5]\n",
    "                class_name = \"\"\n",
    "                for name in line_split[:-5]:\n",
    "                    class_name += name + \" \"\n",
    "                class_name = class_name[:-1]\n",
    "                is_difficult = True\n",
    "            else:\n",
    "                line_split = line.split()\n",
    "                bottom = line_split[-1]\n",
    "                right = line_split[-2]\n",
    "                top = line_split[-3]\n",
    "                left = line_split[-4]\n",
    "                class_name = \"\"\n",
    "                for name in line_split[:-4]:\n",
    "                    class_name += name + \" \"\n",
    "                class_name = class_name[:-1]\n",
    "        if class_name in args.ignore:\n",
    "            continue\n",
    "        bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "        if is_difficult:\n",
    "                bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False, \"difficult\":True})\n",
    "                is_difficult = False\n",
    "        else:\n",
    "                bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "                if class_name in gt_counter_per_class:\n",
    "                    gt_counter_per_class[class_name] += 1\n",
    "                else:\n",
    "                    gt_counter_per_class[class_name] = 1\n",
    "\n",
    "                if class_name not in already_seen_classes:\n",
    "                    if class_name in counter_images_per_class:\n",
    "                        counter_images_per_class[class_name] += 1\n",
    "                    else:\n",
    "                        counter_images_per_class[class_name] = 1\n",
    "                    already_seen_classes.append(class_name)\n",
    "\n",
    "\n",
    "    with open(TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "\n",
    "gt_classes = list(gt_counter_per_class.keys())\n",
    "gt_classes = sorted(gt_classes)\n",
    "n_classes = len(gt_classes)\n",
    "\n",
    "#\"\"\"\n",
    "# Check format of the flag --set-class-iou (if used)\n",
    "#    e.g. check if class exists\n",
    "#\"\"\"\n",
    "if specific_iou_flagged:\n",
    "    n_args = len(args.set_class_iou)\n",
    "    error_msg = \\\n",
    "        '\\n --set-class-iou [class_1] [IoU_1] [class_2] [IoU_2] [...]'\n",
    "    if n_args % 2 != 0:\n",
    "        error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "    # [class_1] [IoU_1] [class_2] [IoU_2]\n",
    "    # specific_iou_classes = ['class_1', 'class_2']\n",
    "    specific_iou_classes = args.set_class_iou[::2] # even\n",
    "    # iou_list = ['IoU_1', 'IoU_2']\n",
    "    iou_list = args.set_class_iou[1::2] # odd\n",
    "    if len(specific_iou_classes) != len(iou_list):\n",
    "        error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "    for tmp_class in specific_iou_classes:\n",
    "        if tmp_class not in gt_classes:\n",
    "                    error('Error, unknown class \\\"' + tmp_class + '\\\". Flag usage:' + error_msg)\n",
    "    for num in iou_list:\n",
    "        if not is_float_between_0_and_1(num):\n",
    "            error('Error, IoU must be between 0.0 and 1.0. Flag usage:' + error_msg)\n",
    "\n",
    "#\"\"\"\n",
    "# detection-results\n",
    "#     Load each of the detection-results files into a temporary \".json\" file.\n",
    "#\"\"\"\n",
    "dr_files_list = glob.glob(DR_PATH + '/*.txt')\n",
    "dr_files_list.sort()\n",
    "\n",
    "for class_index, class_name in enumerate(gt_classes):\n",
    "    bounding_boxes = []\n",
    "    for txt_file in dr_files_list:\n",
    "        file_id = txt_file.split(\".txt\",1)[0]\n",
    "        file_id = os.path.basename(os.path.normpath(file_id))\n",
    "        temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n",
    "        if class_index == 0:\n",
    "            if not os.path.exists(temp_path):\n",
    "                error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "                error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "                error(error_msg)\n",
    "        lines = file_lines_to_list(txt_file)\n",
    "        for line in lines:\n",
    "            try:\n",
    "                tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "            except:\n",
    "                line_split = line.split()\n",
    "                bottom = line_split[-1]\n",
    "                right = line_split[-2]\n",
    "                top = line_split[-3]\n",
    "                left = line_split[-4]\n",
    "                confidence = line_split[-5]\n",
    "                tmp_class_name = \"\"\n",
    "                for name in line_split[:-5]:\n",
    "                    tmp_class_name += name + \" \"\n",
    "                tmp_class_name = tmp_class_name[:-1]\n",
    "\n",
    "            if tmp_class_name == class_name:\n",
    "                bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "                bounding_boxes.append({\"confidence\":confidence, \"file_id\":file_id, \"bbox\":bbox})\n",
    "\n",
    "    bounding_boxes.sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "    with open(TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "\n",
    "#\"\"\"\n",
    "# Calculate the AP for each class\n",
    "#\"\"\"\n",
    "sum_AP = 0.0\n",
    "ap_dictionary = {}\n",
    "lamr_dictionary = {}\n",
    "with open(results_files_path + \"/results.txt\", 'w') as results_file:\n",
    "    results_file.write(\"# AP and precision/recall per class\\n\")\n",
    "    count_true_positives = {}\n",
    "\n",
    "    for class_index, class_name in enumerate(gt_classes):\n",
    "        count_true_positives[class_name] = 0\n",
    "        \"\"\"\n",
    "         Load detection-results of that class\n",
    "        \"\"\"\n",
    "        dr_file = TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\"\n",
    "        dr_data = json.load(open(dr_file))\n",
    "        \"\"\"\n",
    "         Assign detection-results to ground-truth objects\n",
    "        \"\"\"\n",
    "        nd = len(dr_data)\n",
    "        tp = [0] * nd\n",
    "        fp = [0] * nd\n",
    "        score = [0] * nd\n",
    "        score05_idx = 0\n",
    "        for idx, detection in enumerate(dr_data):\n",
    "            file_id = detection[\"file_id\"]\n",
    "            score[idx]   = float(detection[\"confidence\"])\n",
    "            if score[idx] > 0.5:\n",
    "                score05_idx = idx\n",
    "\n",
    "            if show_animation:\n",
    "                ground_truth_img = glob.glob1(IMG_PATH, file_id + \".*\")\n",
    "                if len(ground_truth_img) == 0:\n",
    "                    error(\"Error. Image not found with id: \" + file_id)\n",
    "                elif len(ground_truth_img) > 1:\n",
    "                    error(\"Error. Multiple image with id: \" + file_id)\n",
    "                else:\n",
    "                    img = cv2.imread(IMG_PATH + \"/\" + ground_truth_img[0])\n",
    "                    img_cumulative_path = results_files_path + \"/images/\" + ground_truth_img[0]\n",
    "                    if os.path.isfile(img_cumulative_path):\n",
    "                        img_cumulative = cv2.imread(img_cumulative_path)\n",
    "                    else:\n",
    "                        img_cumulative = img.copy()\n",
    "                    bottom_border = 60\n",
    "                    BLACK = [0, 0, 0]\n",
    "                    img = cv2.copyMakeBorder(img, 0, bottom_border, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "\n",
    "            gt_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "            ground_truth_data = json.load(open(gt_file))\n",
    "            ovmax = -1\n",
    "            gt_match = -1\n",
    "            bb = [ float(x) for x in detection[\"bbox\"].split() ]\n",
    "            for obj in ground_truth_data:\n",
    "                if obj[\"class_name\"] == class_name:\n",
    "                    bbgt = [ float(x) for x in obj[\"bbox\"].split() ]\n",
    "                    bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "                    iw = bi[2] - bi[0] + 1\n",
    "                    ih = bi[3] - bi[1] + 1\n",
    "                    if iw > 0 and ih > 0:\n",
    "                        # compute overlap (IoU) = area of intersection / area of union\n",
    "                        ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                                        + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                        ov = iw * ih / ua\n",
    "                        if ov > ovmax:\n",
    "                            ovmax = ov\n",
    "                            gt_match = obj\n",
    "\n",
    "            if show_animation:\n",
    "                status = \"NO MATCH FOUND!\" \n",
    "            min_overlap = MINOVERLAP\n",
    "            if specific_iou_flagged:\n",
    "                if class_name in specific_iou_classes:\n",
    "                    index = specific_iou_classes.index(class_name)\n",
    "                    min_overlap = float(iou_list[index])\n",
    "            if ovmax >= min_overlap:\n",
    "                if \"difficult\" not in gt_match:\n",
    "                    if not bool(gt_match[\"used\"]):\n",
    "                        tp[idx] = 1\n",
    "                        gt_match[\"used\"] = True\n",
    "                        count_true_positives[class_name] += 1\n",
    "                        with open(gt_file, 'w') as f:\n",
    "                                f.write(json.dumps(ground_truth_data))\n",
    "                        if show_animation:\n",
    "                            status = \"MATCH!\"\n",
    "                    else:\n",
    "                        fp[idx] = 1\n",
    "                        if show_animation:\n",
    "                            status = \"REPEATED MATCH!\"\n",
    "            else:\n",
    "                fp[idx] = 1\n",
    "                if ovmax > 0:\n",
    "                    status = \"INSUFFICIENT OVERLAP\"\n",
    "\n",
    "#            \"\"\"\n",
    "#             Draw image to show animation\n",
    "#            \"\"\"\n",
    "            if show_animation:\n",
    "                height, widht = img.shape[:2]\n",
    "                # colors (OpenCV works with BGR)\n",
    "                white = (255,255,255)\n",
    "                light_blue = (255,200,100)\n",
    "                green = (0,255,0)\n",
    "                light_red = (30,30,255)\n",
    "                # 1st line\n",
    "                margin = 10\n",
    "                v_pos = int(height - margin - (bottom_border / 2.0))\n",
    "                text = \"Image: \" + ground_truth_img[0] + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                text = \"Class [\" + str(class_index) + \"/\" + str(n_classes) + \"]: \" + class_name + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), light_blue, line_width)\n",
    "                if ovmax != -1:\n",
    "                    color = light_red\n",
    "                    if status == \"INSUFFICIENT OVERLAP\":\n",
    "                        text = \"IoU: {0:.2f}% \".format(ovmax*100) + \"< {0:.2f}% \".format(min_overlap*100)\n",
    "                    else:\n",
    "                        text = \"IoU: {0:.2f}% \".format(ovmax*100) + \">= {0:.2f}% \".format(min_overlap*100)\n",
    "                        color = green\n",
    "                    img, _ = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "                # 2nd line\n",
    "                v_pos += int(bottom_border / 2.0)\n",
    "                rank_pos = str(idx+1) # rank position (idx starts at 0)\n",
    "                text = \"Detection #rank: \" + rank_pos + \" confidence: {0:.2f}% \".format(float(detection[\"confidence\"])*100)\n",
    "                img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                color = light_red\n",
    "                if status == \"MATCH!\":\n",
    "                    color = green\n",
    "                text = \"Result: \" + status + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                if ovmax > 0: # if there is intersections between the bounding-boxes\n",
    "                    bbgt = [ int(round(float(x))) for x in gt_match[\"bbox\"].split() ]\n",
    "                    cv2.rectangle(img,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                    cv2.rectangle(img_cumulative,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                    cv2.putText(img_cumulative, class_name, (bbgt[0],bbgt[1] - 5), font, 0.6, light_blue, 1, cv2.LINE_AA)\n",
    "                bb = [int(i) for i in bb]\n",
    "                cv2.rectangle(img,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                cv2.rectangle(img_cumulative,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                cv2.putText(img_cumulative, class_name, (bb[0],bb[1] - 5), font, 0.6, color, 1, cv2.LINE_AA)\n",
    "                # show image\n",
    "                #cv2.namedWindow(\"Animation\")\n",
    "                #cv2.imshow(\"Animation\", img)\n",
    "               # cvShowImage('Animation',img)\n",
    "                #cv2.waitKey(20)# show for 20 ms\n",
    "                #cv2.destroyAllWindows()\n",
    "                # save image to results\n",
    "                output_img_path = results_files_path + \"/images/detections_one_by_one/\" + class_name + \"_detection\" + str(idx) + \".jpg\"\n",
    "                cv2.imwrite(output_img_path, img)\n",
    "                # save the image with all the objects drawn to it\n",
    "                cv2.imwrite(img_cumulative_path, img_cumulative)\n",
    "\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(fp):\n",
    "            fp[idx] += cumsum\n",
    "            cumsum += val\n",
    "\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(tp):\n",
    "            tp[idx] += cumsum\n",
    "            cumsum += val\n",
    "\n",
    "        rec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            rec[idx] = float(tp[idx]) / np.maximum(gt_counter_per_class[class_name], 1)\n",
    "\n",
    "        prec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            prec[idx] = float(tp[idx]) / np.maximum((fp[idx] + tp[idx]), 1)\n",
    "\n",
    "        ap, mrec, mprec = voc_ap(rec[:], prec[:])\n",
    "        F1 = np.array(rec)*np.array(prec)*2 / np.where((np.array(prec)+np.array(rec))==0, 1, (np.array(prec)+np.array(rec)))\n",
    "\n",
    "        sum_AP += ap\n",
    "        text = \"{0:.2f}%\".format(ap*100) + \" = \" + class_name + \" AP \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "\n",
    "        if len(prec)>0:\n",
    "            F1_text = \"{0:.2f}\".format(F1[score05_idx]) + \" = \" + class_name + \" F1 \"\n",
    "            Recall_text = \"{0:.2f}%\".format(rec[score05_idx]*100) + \" = \" + class_name + \" Recall \"\n",
    "            Precision_text = \"{0:.2f}%\".format(prec[score05_idx]*100) + \" = \" + class_name + \" Precision \"\n",
    "        else:\n",
    "            F1_text = \"0.00\" + \" = \" + class_name + \" F1 \" \n",
    "            Recall_text = \"0.00%\" + \" = \" + class_name + \" Recall \" \n",
    "            Precision_text = \"0.00%\" + \" = \" + class_name + \" Precision \" \n",
    "\n",
    "        rounded_prec = [ '%.2f' % elem for elem in prec ]\n",
    "        rounded_rec = [ '%.2f' % elem for elem in rec ]\n",
    "        results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "        if not args.quiet:\n",
    "            if len(prec)>0:\n",
    "                print(text + \"\\t||\\tscore_threhold=0.5 : \" + \"F1=\" + \"{0:.2f}\".format(F1[score05_idx])\\\n",
    "                    + \" ; Recall=\" + \"{0:.2f}%\".format(rec[score05_idx]*100) + \" ; Precision=\" + \"{0:.2f}%\".format(prec[score05_idx]*100))\n",
    "            else:\n",
    "                print(text + \"\\t||\\tscore_threhold=0.5 : F1=0.00% ; Recall=0.00% ; Precision=0.00%\")\n",
    "        ap_dictionary[class_name] = ap\n",
    "\n",
    "        n_images = counter_images_per_class[class_name]\n",
    "        lamr, mr, fppi = log_average_miss_rate(np.array(rec), np.array(fp), n_images)\n",
    "        lamr_dictionary[class_name] = lamr\n",
    "\n",
    "#        \"\"\"\n",
    "#         Draw plot\n",
    "#        \"\"\"\n",
    "        if draw_plot:\n",
    "            plt.plot(rec, prec, '-o')\n",
    "            area_under_curve_x = mrec[:-1] + [mrec[-2]] + [mrec[-1]]\n",
    "            area_under_curve_y = mprec[:-1] + [0.0] + [mprec[-1]]\n",
    "            plt.fill_between(area_under_curve_x, 0, area_under_curve_y, alpha=0.2, edgecolor='r')\n",
    "\n",
    "            fig = plt.gcf()\n",
    "            fig.canvas.set_window_title('AP ' + class_name)\n",
    "\n",
    "            plt.title('class: ' + text)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05]) \n",
    "            fig.savefig(results_files_path + \"/AP/\" + class_name + \".png\")\n",
    "            plt.cla()\n",
    "\n",
    "            plt.plot(score, F1, \"-\", color='orangered')\n",
    "            plt.title('class: ' + F1_text + \"\\nscore_threhold=0.5\")\n",
    "            plt.xlabel('Score_Threhold')\n",
    "            plt.ylabel('F1')\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05])\n",
    "            fig.savefig(results_files_path + \"/F1/\" + class_name + \".png\")\n",
    "            plt.cla()\n",
    "\n",
    "            plt.plot(score, rec, \"-H\", color='gold')\n",
    "            plt.title('class: ' + Recall_text + \"\\nscore_threhold=0.5\")\n",
    "            plt.xlabel('Score_Threhold')\n",
    "            plt.ylabel('Recall')\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05])\n",
    "            fig.savefig(results_files_path + \"/Recall/\" + class_name + \".png\")\n",
    "            plt.cla()\n",
    "\n",
    "            plt.plot(score, prec, \"-s\", color='palevioletred')\n",
    "            plt.title('class: ' + Precision_text + \"\\nscore_threhold=0.5\")\n",
    "            plt.xlabel('Score_Threhold')\n",
    "            plt.ylabel('Precision')\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05])\n",
    "            fig.savefig(results_files_path + \"/Precision/\" + class_name + \".png\")\n",
    "            plt.cla()\n",
    "            \n",
    "   # if show_animation:\n",
    "    #    cv2.destroyAllWindows()\n",
    "\n",
    "    results_file.write(\"\\n# mAP of all classes\\n\")\n",
    "    mAP = sum_AP / n_classes\n",
    "    text = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    results_file.write(text + \"\\n\")\n",
    "    print(text)\n",
    "\n",
    "# remove the temp_files directory\n",
    "shutil.rmtree(TEMP_FILES_PATH)\n",
    "\n",
    "#\"\"\"\n",
    "# Count total of detection-results\n",
    "#\"\"\"\n",
    "# iterate through all the files\n",
    "det_counter_per_class = {}\n",
    "for txt_file in dr_files_list:\n",
    "    # get lines to list\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    for line in lines_list:\n",
    "        class_name = line.split()[0]\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "            continue\n",
    "        # count that object\n",
    "        if class_name in det_counter_per_class:\n",
    "            det_counter_per_class[class_name] += 1\n",
    "        else:\n",
    "            # if class didn't exist yet\n",
    "            det_counter_per_class[class_name] = 1\n",
    "#print(det_counter_per_class)\n",
    "dr_classes = list(det_counter_per_class.keys())\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "# Plot the total number of occurences of each class in the ground-truth\n",
    "#\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"ground-truth-info\"\n",
    "    plot_title = \"ground-truth\\n\"\n",
    "    plot_title += \"(\" + str(len(ground_truth_files_list)) + \" files and \" + str(n_classes) + \" classes)\"\n",
    "    x_label = \"Number of objects per class\"\n",
    "    output_path = results_files_path + \"/ground-truth-info.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'forestgreen'\n",
    "    draw_plot_func(\n",
    "        gt_counter_per_class,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        '',\n",
    "        )\n",
    "\n",
    "#\"\"\"\n",
    "# Write number of ground-truth objects per class to results.txt\n",
    "#\"\"\"\n",
    "with open(results_files_path + \"/results.txt\", 'a') as results_file:\n",
    "    results_file.write(\"\\n# Number of ground-truth objects per class\\n\")\n",
    "    for class_name in sorted(gt_counter_per_class):\n",
    "        results_file.write(class_name + \": \" + str(gt_counter_per_class[class_name]) + \"\\n\")\n",
    "\n",
    "#\"\"\"\n",
    "# Finish counting true positives\n",
    "#\"\"\"\n",
    "for class_name in dr_classes:\n",
    "    # if class exists in detection-result but not in ground-truth then there are no true positives in that class\n",
    "    if class_name not in gt_classes:\n",
    "        count_true_positives[class_name] = 0\n",
    "#print(count_true_positives)\n",
    "\n",
    "#\"\"\"\n",
    "# Plot the total number of occurences of each class in the \"detection-results\" folder\n",
    "#\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"detection-results-info\"\n",
    "    # Plot title\n",
    "    plot_title = \"detection-results\\n\"\n",
    "    plot_title += \"(\" + str(len(dr_files_list)) + \" files and \"\n",
    "    count_non_zero_values_in_dictionary = sum(int(x) > 0 for x in list(det_counter_per_class.values()))\n",
    "    plot_title += str(count_non_zero_values_in_dictionary) + \" detected classes)\"\n",
    "    # end Plot title\n",
    "    x_label = \"Number of objects per class\"\n",
    "    output_path = results_files_path + \"/detection-results-info.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'forestgreen'\n",
    "    true_p_bar = count_true_positives\n",
    "    draw_plot_func(\n",
    "        det_counter_per_class,\n",
    "        len(det_counter_per_class),\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        true_p_bar\n",
    "        )\n",
    "\n",
    "#\"\"\"\n",
    "# Write number of detected objects per class to results.txt\n",
    "#\"\"\"\n",
    "with open(results_files_path + \"/results.txt\", 'a') as results_file:\n",
    "    results_file.write(\"\\n# Number of detected objects per class\\n\")\n",
    "    for class_name in sorted(dr_classes):\n",
    "        n_det = det_counter_per_class[class_name]\n",
    "        text = class_name + \": \" + str(n_det)\n",
    "        text += \" (tp:\" + str(count_true_positives[class_name]) + \"\"\n",
    "        text += \", fp:\" + str(n_det - count_true_positives[class_name]) + \")\\n\"\n",
    "        results_file.write(text)\n",
    "\n",
    "#\"\"\"\n",
    "# Draw log-average miss rate plot (Show lamr of all classes in decreasing order)\n",
    "#\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"lamr\"\n",
    "    plot_title = \"log-average miss rate\"\n",
    "    x_label = \"log-average miss rate\"\n",
    "    output_path = results_files_path + \"/lamr.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'royalblue'\n",
    "    draw_plot_func(\n",
    "        lamr_dictionary,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        \"\"\n",
    "        )\n",
    "\n",
    "#\"\"\"\n",
    "# Draw mAP plot (Show AP's of all classes in decreasing order)\n",
    "#\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"mAP\"\n",
    "    plot_title = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    x_label = \"Average Precision\"\n",
    "    output_path = results_files_path + \"/mAP.png\"\n",
    "    to_show = True\n",
    "    plot_color = 'royalblue'\n",
    "    draw_plot_func(\n",
    "        ap_dictionary,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        \"\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO/3SiA1JXRLx02o4Ygsscw",
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
